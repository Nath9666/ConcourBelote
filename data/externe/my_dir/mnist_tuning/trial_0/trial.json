{
  "trial_id": "0",
  "hyperparameters": {
    "space": [
      {
        "class_name": "Int",
        "config": {
          "name": "conv_1_filter",
          "default": null,
          "conditions": [],
          "min_value": 32,
          "max_value": 128,
          "step": 16,
          "sampling": "linear"
        }
      },
      {
        "class_name": "Choice",
        "config": {
          "name": "conv_1_kernel",
          "default": 3,
          "conditions": [],
          "values": [3, 5],
          "ordered": true
        }
      },
      {
        "class_name": "Int",
        "config": {
          "name": "conv_2_filter",
          "default": null,
          "conditions": [],
          "min_value": 32,
          "max_value": 128,
          "step": 16,
          "sampling": "linear"
        }
      },
      {
        "class_name": "Choice",
        "config": {
          "name": "conv_2_kernel",
          "default": 3,
          "conditions": [],
          "values": [3, 5],
          "ordered": true
        }
      },
      {
        "class_name": "Int",
        "config": {
          "name": "conv_3_filter",
          "default": null,
          "conditions": [],
          "min_value": 32,
          "max_value": 128,
          "step": 16,
          "sampling": "linear"
        }
      },
      {
        "class_name": "Choice",
        "config": {
          "name": "conv_3_kernel",
          "default": 3,
          "conditions": [],
          "values": [3, 5],
          "ordered": true
        }
      },
      {
        "class_name": "Int",
        "config": {
          "name": "dense_units",
          "default": null,
          "conditions": [],
          "min_value": 32,
          "max_value": 128,
          "step": 16,
          "sampling": "linear"
        }
      }
    ],
    "values": {
      "conv_1_filter": 32,
      "conv_1_kernel": 3,
      "conv_2_filter": 112,
      "conv_2_kernel": 5,
      "conv_3_filter": 48,
      "conv_3_kernel": 5,
      "dense_units": 80
    }
  },
  "metrics": { "metrics": {} },
  "score": null,
  "best_step": 0,
  "status": "FAILED",
  "message": "Traceback (most recent call last):\n  File \"c:\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"c:\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"c:\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 124, in error_handler\n    del filtered_tb\nValueError: Exception encountered when calling Conv2D.call().\n\n\u001b[1mNegative dimension size caused by subtracting 5 from 4 for '{{node sequential_1/conv2d_2_1/convolution}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](sequential_1/max_pooling2d_1_2/MaxPool2d, sequential_1/conv2d_2_1/convolution/ReadVariableOp)' with input shapes: [32,4,4,112], [5,5,112,48].\u001b[0m\n\nArguments received by Conv2D.call():\n  \u2022 inputs=tf.Tensor(shape=(32, 4, 4, 112), dtype=float32)\n"
}
